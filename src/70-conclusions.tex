This thesis has researched how to review large numbers of program code submissions more efficiently than manually reviewing them. As an additional contribution, a new system was developed, CodeClusters, that implements some of the researched methods and which aims to offer an approach for teachers to analyze, explore and provide feedback to student submissions. The system, the problem and the ideas of using search or modeling to analyze the submissions were studied as interviews with teachers who had experience in teaching programming courses. The results of the questionnaires, performed tasks with the system as well as the overall commentary during the interviews were analyzed and discussed in the context of the research questions. The system was also evaluated for UI and system design criteria.

The results indicate that the teachers do not have similar existing systems to analyze the submissions and that the designed system would allow novel opportunities for deepening teachers' knowledge about the student programming patterns. All the interviewed teachers expressed interest in using the system with programming courses they teach, and the overall impressions were positive. Therefore, the system seems to have achieved its goal of being potentially very useful to the teachers. However, further software development and research is needed to improve the system and the proposed similarity detection model.

CodeClusters in itself is a well-documented and working prototype, developed with popular technologies and libraries such as Docker, Node.js, React, TypeScript, Python, Postgres, Nginx and Solr. It offers a robust groundwork for further development and while it became evident during the interviews that some UI enhancements are required to improve its usability, namely side-by-side comparisons between clusters, the basic approach it implements appears suitable. The search was found to be a good general tool for finding outliers that would scale well to large datasets. The implemented similarity detection model, n-grams, while producing interesting clusters, still requires improvements to better discern higher-level patterns.

Using more features in the model such as CFGs, hierarchically generated n-grams or metrics, could result in improved accuracy in detecting meaningful structural patterns yet this is left as possible future work. Developing the model to detect similarities of different levels might be worthwhile to investigate. Additionally, the system requires alongside the UI enhancements integrations to LMSs as well as support for more programming languages to be used by teachers in programming courses.

Possible applications of this research and system could improve the teachers' overall ability to understand their students' behavior better, as well as improving the learning of students and course material. Analyzing the submissions could help teachers to discern misconceptions, errors in the test suites, anti-patterns and solution schemas students have used. Providing feedback with the system might also be useful, yet sending the feedback after the student submitted their work might not be perceived by students as very relevant. The in-depth knowledge of the student behavior discovered by using a system such as CodeClusters could be used to develop better analysis and feedback systems, such as intelligent tutoring systems, that could provide more holistic feedback as the students are solving the exercises.

\iffalse
The long-term benefits from analyzing the student submissions on a high abstraction level could provide teachers with a more realistic intuition how the exercises are being solved. Combining the system with for example snap-shot based solution progress analysis could allow teachers to precisely find and understand how students flail in the exercises. solve the exercises?
\fi
